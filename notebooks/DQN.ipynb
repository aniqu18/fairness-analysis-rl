{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19e619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN...\n",
      "Epoch 1/40  replay=1645  eps=0.050  avg_loss=0.2239\n",
      "Epoch 5/40  replay=8225  eps=0.050  avg_loss=0.0430\n",
      "Epoch 10/40  replay=16450  eps=0.050  avg_loss=0.0189\n",
      "Epoch 15/40  replay=20000  eps=0.050  avg_loss=0.0100\n",
      "Epoch 20/40  replay=20000  eps=0.050  avg_loss=0.0057\n",
      "Epoch 25/40  replay=20000  eps=0.050  avg_loss=0.0048\n",
      "Epoch 30/40  replay=20000  eps=0.050  avg_loss=0.0046\n",
      "Epoch 35/40  replay=20000  eps=0.050  avg_loss=0.0041\n",
      "Epoch 40/40  replay=20000  eps=0.050  avg_loss=0.0035\n",
      "Model saved to: ../data/dqn_cardiac.pth\n",
      "\n",
      "Overall test metrics:\n",
      "Accuracy: 0.45108695652173914\n",
      "Macro F1: 0.31862595793648846\n",
      "\n",
      "Metrics by sex (sex_Male=1 means male):\n",
      "Group 0: n=32, acc=0.625, macro_f1=0.208\n",
      "   class 0: pred_rate=0.656, recall=0.704, prec=0.905\n",
      "   class 1: pred_rate=0.125, recall=0.250, prec=0.250\n",
      "   class 2: pred_rate=0.094, recall=0.000, prec=0.000\n",
      "   class 3: pred_rate=0.094, recall=0.000, prec=0.000\n",
      "   class 4: pred_rate=0.031, recall=0.000, prec=0.000\n",
      "Group 1: n=152, acc=0.414, macro_f1=0.319\n",
      "   class 0: pred_rate=0.362, recall=0.618, prec=0.618\n",
      "   class 1: pred_rate=0.316, recall=0.408, prec=0.417\n",
      "   class 2: pred_rate=0.145, recall=0.095, prec=0.091\n",
      "   class 3: pred_rate=0.151, recall=0.286, prec=0.261\n",
      "   class 4: pred_rate=0.026, recall=0.167, prec=0.250\n",
      "\n",
      "Disparities (male - female):\n",
      "Accuracy diff: -0.21052631578947367\n",
      "Macro F1 diff: 0.11092736281539922\n",
      " Class 0: pred_rate_diff=-0.294, tpr_diff=-0.086\n",
      " Class 1: pred_rate_diff=0.191, tpr_diff=0.158\n",
      " Class 2: pred_rate_diff=0.051, tpr_diff=0.095\n",
      " Class 3: pred_rate_diff=0.058, tpr_diff=0.286\n",
      " Class 4: pred_rate_diff=-0.005, tpr_diff=0.167\n",
      "\n",
      "Confusion matrices by sex:\n",
      "Group 0 (n=32):\n",
      "[[19  3  2  2  1]\n",
      " [ 1  1  1  1  0]\n",
      " [ 1  0  0  0  0]\n",
      " [ 0  0  0  0  0]\n",
      " [ 0  0  0  0  0]]\n",
      "Group 1 (n=152):\n",
      "[[34 14  4  3  0]\n",
      " [ 9 20 11  7  2]\n",
      " [ 3 10  2  5  1]\n",
      " [ 8  3  4  6  0]\n",
      " [ 1  1  1  2  1]]\n",
      "Could not compute age-based metrics: 'numpy.ndarray' object has no attribute 'values'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/7g/k85gr2ds09vdkh_4yqmhgrkr0000gn/T/ipykernel_93179/3619439765.py:283: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  raw_df[col] = raw_df[col].fillna(raw_df[col].mode()[0])\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "\"\"\"\n",
    "Train a DQN on the preprocessed heart dataset and evaluate fairness by sex and age.\n",
    "Run from repository root:\n",
    "  python3 src/train_dqn_and_fairness.py\n",
    "Assumes Ella_data_processing.ipynb has produced ../data/Xy_train_resampled.csv, X_test.csv, y_test.csv\n",
    "and that the raw dataset is at ../datasets/heart_disease_uci.csv\n",
    "\"\"\"\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# --- CONFIG ---\n",
    "# script is in src/, data dir is one level up\n",
    "DATA_DIR = \"../data\"\n",
    "RAW_DATA = \"../datasets/heart_disease_uci.csv\"\n",
    "MODEL_OUT = os.path.join(DATA_DIR, \"dqn_cardiac.pth\")\n",
    "\n",
    "NUM_ACTIONS = 5        # classes 0..4\n",
    "STATE_DTYPE = np.float32\n",
    "\n",
    "# Hyperparams\n",
    "HIDDEN = [128, 64]\n",
    "LR = 1e-3\n",
    "GAMMA = 0.99\n",
    "BATCH_SIZE = 128\n",
    "REPLAY_CAP = 20000\n",
    "MIN_REPLAY = 256\n",
    "EPS_START, EPS_END, EPS_DECAY = 1.0, 0.05, 0.995\n",
    "NUM_EPOCHS = 40\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Load preprocessed CSVs produced by Ella_data_processing.ipynb ---\n",
    "Xy_train_res_path = os.path.join(DATA_DIR, \"Xy_train_resampled.csv\")\n",
    "X_test_path = os.path.join(DATA_DIR, \"X_test.csv\")\n",
    "y_test_path = os.path.join(DATA_DIR, \"y_test.csv\")\n",
    "\n",
    "for p in (Xy_train_res_path, X_test_path, y_test_path):\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Required file not found: {p}\")\n",
    "\n",
    "Xy_train_res = pd.read_csv(Xy_train_res_path)\n",
    "X_test = pd.read_csv(X_test_path)\n",
    "y_test = pd.read_csv(y_test_path)[\"num\"].values\n",
    "\n",
    "feature_cols = [c for c in X_test.columns]\n",
    "X_train = Xy_train_res[feature_cols].values.astype(STATE_DTYPE)\n",
    "y_train = Xy_train_res[\"num\"].values.astype(int)\n",
    "X_test = X_test[feature_cols].values.astype(STATE_DTYPE)\n",
    "\n",
    "# Identify sex column in feature_cols (one-hot from get_dummies -> sex_Male). fallback to 'sex'\n",
    "if \"sex_Male\" in feature_cols:\n",
    "    sex_idx = feature_cols.index(\"sex_Male\")\n",
    "    test_sex = X_test[:, sex_idx].astype(int)\n",
    "elif \"sex\" in feature_cols:\n",
    "    sex_idx = feature_cols.index(\"sex\")\n",
    "    test_sex = X_test[:, sex_idx].astype(int)\n",
    "else:\n",
    "    test_sex = None\n",
    "    print(\"Warning: no sex column found in features; sex-based metrics will be skipped.\")\n",
    "\n",
    "# --- Simple RL environment (one patient = one episode) ---\n",
    "class CardiacEnv:\n",
    "    def __init__(self, X: np.ndarray, y: np.ndarray):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n = len(X)\n",
    "        self.idx = 0\n",
    "\n",
    "    def reset(self) -> np.ndarray:\n",
    "        state = self.X[self.idx]\n",
    "        self.curr_label = int(self.y[self.idx])\n",
    "        self.idx = (self.idx + 1) % self.n\n",
    "        return state\n",
    "\n",
    "    def step(self, action: int) -> Tuple[np.ndarray, float, bool, dict]:\n",
    "        reward = 1.0 if action == self.curr_label else -1.0\n",
    "        done = True\n",
    "        next_state = np.zeros_like(self.X[0], dtype=STATE_DTYPE)\n",
    "        return next_state, reward, done, {}\n",
    "\n",
    "# --- Replay buffer ---\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity: int):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, s, a, r, s2, done):\n",
    "        self.buffer.append((s, a, r, s2, done))\n",
    "\n",
    "    def sample(self, batch_size: int):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        s, a, r, s2, done = map(np.stack, zip(*batch))\n",
    "        return s, a, r, s2, done\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# --- Q-network ---\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev = input_dim\n",
    "        for h in HIDDEN:\n",
    "            layers.append(nn.Linear(prev, h))\n",
    "            layers.append(nn.ReLU())\n",
    "            prev = h\n",
    "        layers.append(nn.Linear(prev, output_dim))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# --- Agent ---\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_dim, n_actions):\n",
    "        self.q = QNet(state_dim, n_actions).to(DEVICE)\n",
    "        self.target_q = QNet(state_dim, n_actions).to(DEVICE)\n",
    "        self.target_q.load_state_dict(self.q.state_dict())\n",
    "        self.opt = optim.Adam(self.q.parameters(), lr=LR)\n",
    "        self.replay = ReplayBuffer(REPLAY_CAP)\n",
    "        self.eps = EPS_START\n",
    "        self.steps = 0\n",
    "\n",
    "    def act(self, state, greedy=False):\n",
    "        if (not greedy) and random.random() < self.eps:\n",
    "            return random.randrange(NUM_ACTIONS)\n",
    "        s = torch.from_numpy(state).float().to(DEVICE).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            qvals = self.q(s)\n",
    "        return int(qvals.argmax().item())\n",
    "\n",
    "    def push(self, *args):\n",
    "        self.replay.push(*args)\n",
    "\n",
    "    def train_step(self):\n",
    "        if len(self.replay) < MIN_REPLAY:\n",
    "            return None\n",
    "        s, a, r, s2, done = self.replay.sample(BATCH_SIZE)\n",
    "        s = torch.from_numpy(s).float().to(DEVICE)\n",
    "        a = torch.from_numpy(a).long().to(DEVICE)\n",
    "        r = torch.from_numpy(r).float().to(DEVICE)\n",
    "        s2 = torch.from_numpy(s2).float().to(DEVICE)\n",
    "        done = torch.from_numpy(done.astype(np.float32)).float().to(DEVICE)\n",
    "\n",
    "        q_vals = self.q(s).gather(1, a.unsqueeze(1)).squeeze(1)\n",
    "        with torch.no_grad():\n",
    "            next_q = self.target_q(s2).max(1)[0]\n",
    "        target = r + GAMMA * (1.0 - done) * next_q\n",
    "\n",
    "        loss = nn.MSELoss()(q_vals, target)\n",
    "        self.opt.zero_grad()\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "\n",
    "        if self.steps % 500 == 0:\n",
    "            self.target_q.load_state_dict(self.q.state_dict())\n",
    "\n",
    "        self.eps = max(EPS_END, self.eps * EPS_DECAY)\n",
    "        self.steps += 1\n",
    "        return loss.item()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.q.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.q.load_state_dict(torch.load(path, map_location=DEVICE))\n",
    "        self.target_q.load_state_dict(self.q.state_dict())\n",
    "\n",
    "# --- Training ---\n",
    "env = CardiacEnv(X_train, y_train)\n",
    "agent = DQNAgent(state_dim=X_train.shape[1], n_actions=NUM_ACTIONS)\n",
    "\n",
    "print(\"Training DQN...\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    losses = []\n",
    "    for _ in range(len(X_train)):\n",
    "        s = env.reset()\n",
    "        a = agent.act(s, greedy=False)\n",
    "        s2, r, done, _ = env.step(a)\n",
    "        agent.push(s, a, r, s2, float(done))\n",
    "        loss = agent.train_step()\n",
    "        if loss is not None:\n",
    "            losses.append(loss)\n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        avg_loss = np.mean(losses) if losses else float(\"nan\")\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS}  replay={len(agent.replay)}  eps={agent.eps:.3f}  avg_loss={avg_loss:.4f}\")\n",
    "\n",
    "agent.save(MODEL_OUT)\n",
    "print(\"Model saved to:\", MODEL_OUT)\n",
    "\n",
    "# --- Evaluation (greedy) ---\n",
    "agent.load(MODEL_OUT)\n",
    "preds = []\n",
    "agent.eps = 0.0\n",
    "for i in range(len(X_test)):\n",
    "    s = X_test[i]\n",
    "    a = agent.act(s, greedy=True)\n",
    "    preds.append(a)\n",
    "preds = np.array(preds)\n",
    "\n",
    "print(\"\\nOverall test metrics:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(\"Macro F1:\", f1_score(y_test, preds, average=\"macro\"))\n",
    "\n",
    "# --- Fairness metrics helpers ---\n",
    "def group_class_metrics(y_true, y_pred, groups, classes=None):\n",
    "    classes = classes if classes is not None else np.unique(y_true)\n",
    "    results = {}\n",
    "    for g in np.unique(groups):\n",
    "        idx = groups == g\n",
    "        yt, yp = y_true[idx], y_pred[idx]\n",
    "        res = {\n",
    "            \"n\": int(len(yt)),\n",
    "            \"accuracy\": float(accuracy_score(yt, yp)),\n",
    "            \"macro_f1\": float(f1_score(yt, yp, average=\"macro\"))\n",
    "        }\n",
    "        for c in classes:\n",
    "            yt_bin = (yt == c).astype(int)\n",
    "            yp_bin = (yp == c).astype(int)\n",
    "            res[f\"precision_class_{c}\"] = float(precision_score(yt_bin, yp_bin, zero_division=0))\n",
    "            res[f\"recall_class_{c}\"] = float(recall_score(yt_bin, yp_bin, zero_division=0))\n",
    "            res[f\"pred_rate_class_{c}\"] = float((yp == c).mean())\n",
    "        results[str(g)] = res\n",
    "    return results\n",
    "\n",
    "# --- Sex-based fairness (if available) ---\n",
    "if test_sex is not None:\n",
    "    groups = test_sex\n",
    "    metrics_by_sex = group_class_metrics(y_test, preds, groups, classes=np.arange(NUM_ACTIONS))\n",
    "    print(\"\\nMetrics by sex (sex_Male=1 means male):\")\n",
    "    for g, met in metrics_by_sex.items():\n",
    "        print(f\"Group {g}: n={met['n']}, acc={met['accuracy']:.3f}, macro_f1={met['macro_f1']:.3f}\")\n",
    "        for c in range(NUM_ACTIONS):\n",
    "            print(f\"   class {c}: pred_rate={met[f'pred_rate_class_{c}']:.3f}, recall={met[f'recall_class_{c}']:.3f}, prec={met[f'precision_class_{c}']:.3f}\")\n",
    "    # disparities male - female if both present\n",
    "    male = metrics_by_sex.get(\"1\")\n",
    "    female = metrics_by_sex.get(\"0\")\n",
    "    if male and female:\n",
    "        print(\"\\nDisparities (male - female):\")\n",
    "        print(\"Accuracy diff:\", male[\"accuracy\"] - female[\"accuracy\"])\n",
    "        print(\"Macro F1 diff:\", male[\"macro_f1\"] - female[\"macro_f1\"])\n",
    "        for c in range(NUM_ACTIONS):\n",
    "            pdiff = male[f\"pred_rate_class_{c}\"] - female[f\"pred_rate_class_{c}\"]\n",
    "            tprdiff = male[f\"recall_class_{c}\"] - female[f\"recall_class_{c}\"]\n",
    "            print(f\" Class {c}: pred_rate_diff={pdiff:.3f}, tpr_diff={tprdiff:.3f}\")\n",
    "    print(\"\\nConfusion matrices by sex:\")\n",
    "    for g in np.unique(groups):\n",
    "        idx = groups == g\n",
    "        cm = confusion_matrix(y_test[idx], preds[idx], labels=np.arange(NUM_ACTIONS))\n",
    "        print(f\"Group {int(g)} (n={cm.sum()}):\\n{cm}\")\n",
    "else:\n",
    "    print(\"\\nSex-based evaluation skipped (no sex column found).\")\n",
    "\n",
    "# --- Age-based fairness ---\n",
    "# Reconstruct the same test split from raw data to extract unscaled ages\n",
    "try:\n",
    "    raw_df = pd.read_csv(RAW_DATA)\n",
    "    raw_df = raw_df.copy()\n",
    "    raw_df = raw_df.drop(['id','dataset'], axis=1, errors='ignore')\n",
    "    raw_df.drop(columns=['thal','ca'], inplace=True, errors='ignore')\n",
    "    raw_df.loc[raw_df['trestbps'] == 0, 'trestbps'] = np.nan\n",
    "    raw_df.loc[raw_df['chol'] == 0, 'chol'] = np.nan\n",
    "    numeric_cols_raw = raw_df.select_dtypes(include=['int64', 'float64']).columns\n",
    "    raw_df[numeric_cols_raw] = raw_df[numeric_cols_raw].fillna(raw_df[numeric_cols_raw].median())\n",
    "    categorical_cols_raw = raw_df.select_dtypes(include=['object']).columns\n",
    "    for col in categorical_cols_raw:\n",
    "        raw_df[col] = raw_df[col].fillna(raw_df[col].mode()[0])\n",
    "    X_raw = raw_df.drop('num', axis=1)\n",
    "    y_raw = raw_df['num']\n",
    "    # replicate train_test_split used in preprocessing (same random_state & stratify)\n",
    "    _, X_test_raw, _, _ = train_test_split(X_raw, y_raw, test_size=0.2, random_state=42, stratify=y_raw)\n",
    "    if 'age' not in X_test_raw.columns:\n",
    "        raise KeyError(\"age column not found in raw dataset\")\n",
    "    test_age_raw = X_test_raw['age'].values\n",
    "    # create age buckets\n",
    "    age_bins = [0, 45, 55, 65, 75, 200]\n",
    "    age_labels = ['<=45', '46-55', '56-65', '66-75', '>75']\n",
    "    age_group = pd.cut(test_age_raw, bins=age_bins, labels=age_labels, include_lowest=True)\n",
    "    age_group_arr = age_group.astype(str).values\n",
    "    metrics_by_age = group_class_metrics(y_test, preds, age_group_arr, classes=np.arange(NUM_ACTIONS))\n",
    "    print(\"\\nMetrics by age group:\")\n",
    "    for g, met in metrics_by_age.items():\n",
    "        print(f\"Age {g}: n={met['n']}, acc={met['accuracy']:.3f}, macro_f1={met['macro_f1']:.3f}\")\n",
    "        for c in range(NUM_ACTIONS):\n",
    "            print(f\"   class {c}: pred_rate={met[f'pred_rate_class_{c}']:.3f}, recall={met[f'recall_class_{c}']:.3f}, prec={met[f'precision_class_{c}']:.3f}\")\n",
    "    # example disparity: oldest vs youngest if both present\n",
    "    if '<=45' in metrics_by_age and '>75' in metrics_by_age:\n",
    "        young = metrics_by_age['<=45']\n",
    "        old = metrics_by_age['>75']\n",
    "        print(\"\\nDisparities (old - young):\")\n",
    "        print(\"Accuracy diff (old - young):\", old[\"accuracy\"] - young[\"accuracy\"])\n",
    "        print(\"Macro F1 diff (old - young):\", old[\"macro_f1\"] - young[\"macro_f1\"])\n",
    "    print(\"\\nConfusion matrices by age group:\")\n",
    "    for g in np.unique(age_group_arr):\n",
    "        idx = (age_group_arr == g)\n",
    "        if idx.sum() == 0:\n",
    "            continue\n",
    "        cm = confusion_matrix(y_test[idx], preds[idx], labels=np.arange(NUM_ACTIONS))\n",
    "        print(f\"Age {g} (n={cm.sum()}):\\n{cm}\")\n",
    "except Exception as e:\n",
    "    print(\"Could not compute age-based metrics:\", str(e))\n",
    "\n",
    "# End of script\n",
    "# ...existing code..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
